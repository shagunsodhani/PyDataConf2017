{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer the notebook on Siamese Networks and Batch Normalisation before using this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why [Skip Connections](https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)\n",
    "\n",
    "\n",
    "## Allow for training deeper networks.\n",
    "\n",
    "## Effective gradient propogation to lower layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://github.com/shagunsodhani/PyDataConf2017/blob/master/assets/resnet.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://github.com/shagunsodhani/PyDataConf2017/blob/master/assets/resnet.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_dataset = \"/home/shagun/FortKnox/Quora/quora_duplicate_questions.tsv\"\n",
    "path_to_glove_vectors = \"/home/shagun/models/GloVe/glove.6B.100d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "embedding_dim = 100\n",
    "# Refer the exploratory notebook to see how max_len value is arrived at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of question pairs =  404290\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a pandas dataframe\n",
    "df = pd.read_csv(path_to_dataset, delimiter=\"\\t\")\n",
    "print(\"Total number of question pairs = \", str(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>294721</th>\n",
       "      <td>294721</td>\n",
       "      <td>416674</td>\n",
       "      <td>416675</td>\n",
       "      <td>Who was the first person to draw the map of th...</td>\n",
       "      <td>What are some tricks to remember world map?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225481</th>\n",
       "      <td>225481</td>\n",
       "      <td>207353</td>\n",
       "      <td>333822</td>\n",
       "      <td>Why does hydrogen fluoride have a higher boili...</td>\n",
       "      <td>What is the boiling point of hydrogen flouride?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230318</th>\n",
       "      <td>230318</td>\n",
       "      <td>339814</td>\n",
       "      <td>339815</td>\n",
       "      <td>Which film will you watch on 12th August 2016:...</td>\n",
       "      <td>Which film will you watch this weekend: Rustom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371157</th>\n",
       "      <td>371157</td>\n",
       "      <td>501762</td>\n",
       "      <td>501763</td>\n",
       "      <td>Is it better for health to drink a little bit ...</td>\n",
       "      <td>How do I really know if I'm an alcoholic or if...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147305</th>\n",
       "      <td>147305</td>\n",
       "      <td>232510</td>\n",
       "      <td>232511</td>\n",
       "      <td>What is the difference between evaporation and...</td>\n",
       "      <td>What is the main difference between something ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "294721  294721  416674  416675   \n",
       "225481  225481  207353  333822   \n",
       "230318  230318  339814  339815   \n",
       "371157  371157  501762  501763   \n",
       "147305  147305  232510  232511   \n",
       "\n",
       "                                                question1  \\\n",
       "294721  Who was the first person to draw the map of th...   \n",
       "225481  Why does hydrogen fluoride have a higher boili...   \n",
       "230318  Which film will you watch on 12th August 2016:...   \n",
       "371157  Is it better for health to drink a little bit ...   \n",
       "147305  What is the difference between evaporation and...   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "294721        What are some tricks to remember world map?             0  \n",
       "225481    What is the boiling point of hydrogen flouride?             0  \n",
       "230318  Which film will you watch this weekend: Rustom...             1  \n",
       "371157  How do I really know if I'm an alcoholic or if...             0  \n",
       "147305  What is the main difference between something ...             0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us look at a sample of the dataset\n",
    "df_sample = df.sample(5)\n",
    "\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will play with a very small sample of this dataset to save on time. Feel free to train the network on the entire data later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = list(df['is_duplicate'].apply(lambda x: int(x)).values)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of all the question pairs\n",
    "first_question_list = list(df['question1'].apply(lambda x: str(x)).values)\n",
    "second_question_list = list(df['question2'].apply(lambda x: str(x)).values)\n",
    "question_list = list(zip(first_question_list, second_question_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(question_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/shagunsodhani/PyDataConf2017/master/assets/keras-tensorflow-logo.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://raw.githubusercontent.com/shagunsodhani/PyDataConf2017/master/assets/keras-tensorflow-logo.jpg\")\n",
    "# Image taken from: https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from utils.util import *\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers import Embedding, Input, GRU, Dense, Activation, Lambda, BatchNormalization\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(first_question_list + second_question_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence1 = pad_sequences(tokenizer.texts_to_sequences(first_question_list), maxlen=max_len)\n",
    "sequence2 = pad_sequences(tokenizer.texts_to_sequences(second_question_list), maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good to go\n"
     ]
    }
   ],
   "source": [
    "if(len(sequence1) == len(sequence2)):\n",
    "    print(\"Good to go\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Basic ML Preprocessing\n",
    "indices = np.arange(len(sequence1))\n",
    "np.random.shuffle(indices)\n",
    "sequence1 = sequence1[indices]\n",
    "sequence2 = sequence2[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(0.3 * len(sequence1))\n",
    "\n",
    "sequence1_train = sequence1[:-nb_validation_samples]\n",
    "sequence2_train = sequence2[:-nb_validation_samples]\n",
    "labels_train = labels[:-nb_validation_samples]\n",
    "sequence1_val = sequence1[-nb_validation_samples:]\n",
    "sequence2_val = sequence2[-nb_validation_samples:]\n",
    "labels_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 7000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples: \" + str(len(sequence1_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation examples: 3000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of validation examples: \" + str(len(sequence1_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "embeddings_index = get_glove_embeddings(path_to_glove_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the embedding matrix which our model would use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preparing the embedding matrix which our model would use\n",
    "word_index = tokenizer.word_index\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the question into a vector space using a Bidirectional GRU (or LSTM or whatever RNN you believe in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def question_encoder():\n",
    "    return Bidirectional(GRU(units=200), merge_mode='concat', name=\"bidir_gru\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next part is the core of this network and we would walk through it slowly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_question_network():\n",
    "    \n",
    "#     Create an input layer\n",
    "    sequence_input = Input(shape=(max_len,), dtype='int32', name=\"input_layer\")\n",
    "    \n",
    "#     Create an embedding layer\n",
    "    embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            embedding_dim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_len,\n",
    "                            mask_zero = True,\n",
    "                            trainable=False)\n",
    "    \n",
    "#     Use the embedding layer we just created\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    \n",
    "#     Embeddings are for words, sentences uses encoders\n",
    "    encoded_question = question_encoder()(embedded_sequences)\n",
    "    \n",
    "#     Lets fully connect them\n",
    "    dense1 = Dense(64)(encoded_question)\n",
    "#     BatchNormalization\n",
    "    bn1 = BatchNormalization()(dense1)\n",
    "    relu1 = Activation('relu')(bn1)\n",
    "    \n",
    "#    Make it deep\n",
    "    dense2 = Dense(64)(relu1)\n",
    "#     BatchNormalization\n",
    "    bn2 = BatchNormalization()(dense2)\n",
    "#     Skip Connection\n",
    "    res2 = add([relu1, bn2])\n",
    "    relu2 = Activation('relu')(res2)    \n",
    "\n",
    "#     And Deeper\n",
    "    dense3 = Dense(64)(relu2)\n",
    "#     BatchNormalization\n",
    "    bn3 = BatchNormalization()(dense3)\n",
    "#     Skip Connection\n",
    "    res3 = add([relu2, bn3])\n",
    "    relu3 = Activation('relu')(res3)\n",
    "\n",
    "#     Now we are in rythm\n",
    "    dense4 = Dense(64)(relu3)\n",
    "#     BatchNormalization\n",
    "    bn4 = BatchNormalization()(dense4)\n",
    "#     Skip Connection\n",
    "    res4 = add([relu3, bn4])\n",
    "    relu4 = Activation('relu')(bn4)\n",
    "\n",
    "    features = concatenate([relu4, relu3, relu2, relu1])\n",
    "#     BatchNormalization\n",
    "    output = BatchNormalization()(features)\n",
    "    \n",
    "    model = Model(inputs=sequence_input, outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will make the siamese twin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_network():\n",
    "    # network definition\n",
    "    question_network = create_question_network()\n",
    "    \n",
    "#     input to the first head of the network\n",
    "    input1 = Input(shape=(max_len,))\n",
    "    \n",
    "#     input to the second head of the network\n",
    "    input2 = Input(shape=(max_len,))\n",
    "    \n",
    "#     processing the first input\n",
    "    processed1 = question_network(input1)\n",
    "    \n",
    "#     processing the second input\n",
    "    processed2 = question_network(input2)\n",
    "    \n",
    "#     Computing the distance between the transformed inputs.\n",
    "    distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed1, processed2])\n",
    "\n",
    "    \n",
    "    model = Model(inputs=[input1, input2], outputs=distance)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/1\n",
      "1536/7000 [=====>........................] - ETA: 79s - loss: 107.2517"
     ]
    }
   ],
   "source": [
    "model = create_network()\n",
    "\n",
    "optimizer = Adam(lr=0.001, clipnorm=5)\n",
    "model.compile(loss=contrastive_loss, optimizer=optimizer)\n",
    "\n",
    "for i in range(10):\n",
    "    model.fit([sequence1_train, sequence2_train], labels_train,\n",
    "       validation_data=([sequence1_val, sequence2_val], labels_val),\n",
    "       batch_size=128, epochs=1)\n",
    "    \n",
    "    model_labels_train = model.predict([sequence1_train, sequence2_train], batch_size=128)\n",
    "    print(\"Training accuracy: \"+str(compute_accuracy(model_labels_train, labels_train)))\n",
    "    \n",
    "    model_labels_val = model.predict([sequence1_val, sequence2_val], batch_size=128)\n",
    "    print(\"Validation accuracy: \"+str(compute_accuracy(model_labels_val, labels_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_labels_val.ravel() < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(np.equal(model_labels_val.ravel() < 0.5, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compute_accuracy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
