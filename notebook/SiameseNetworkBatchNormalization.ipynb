{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer the notebook on Siamese Networks before using this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why [Batch Normalisation](https://gist.github.com/shagunsodhani/4441216a298df0fe6ab0)\n",
    "\n",
    "\n",
    "## Makes the network robust to bad initialization.\n",
    "\n",
    "## Takes care of Internal Covariate shift.\n",
    "\n",
    "## Think of it as preprocessing at every layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Batch Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/shagunsodhani/PyDataConf2017/master/assets/bneq1.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://raw.githubusercontent.com/shagunsodhani/PyDataConf2017/master/assets/bneq1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oops Wrong Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/shagunsodhani/PyDataConf2017/master/assets/bn_algorithm.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://raw.githubusercontent.com/shagunsodhani/PyDataConf2017/master/assets/bn_algorithm.PNG\")\n",
    "# Image taken from: http://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_dataset = \"/home/shagun/FortKnox/Quora/quora_duplicate_questions.tsv\"\n",
    "path_to_glove_vectors = \"/home/shagun/models/GloVe/glove.6B.100d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "embedding_dim = 100\n",
    "# Refer the exploratory notebook to see how max_len value is arrived at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of question pairs =  404290\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a pandas dataframe\n",
    "df = pd.read_csv(path_to_dataset, delimiter=\"\\t\")\n",
    "print(\"Total number of question pairs = \", str(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>330992</th>\n",
       "      <td>330992</td>\n",
       "      <td>457810</td>\n",
       "      <td>203516</td>\n",
       "      <td>Why do people get white hairs near their temple?</td>\n",
       "      <td>Is there a way to convert some white hair in a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194630</th>\n",
       "      <td>194630</td>\n",
       "      <td>93152</td>\n",
       "      <td>294885</td>\n",
       "      <td>How do you change peoples’ behavior?</td>\n",
       "      <td>What is the best way to change your behavior?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102537</th>\n",
       "      <td>102537</td>\n",
       "      <td>169635</td>\n",
       "      <td>169636</td>\n",
       "      <td>What is it like to live in Texas?</td>\n",
       "      <td>What it's like to live in Texas?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83320</th>\n",
       "      <td>83320</td>\n",
       "      <td>3767</td>\n",
       "      <td>51558</td>\n",
       "      <td>Can you suggest a best budget phone below 15k?</td>\n",
       "      <td>What is the best phone I can get for below 15k?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304304</th>\n",
       "      <td>304304</td>\n",
       "      <td>101579</td>\n",
       "      <td>93681</td>\n",
       "      <td>How can I clear/open/delete messages on Snapchat?</td>\n",
       "      <td>I tried deleting the Snapchat history by selec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "330992  330992  457810  203516   \n",
       "194630  194630   93152  294885   \n",
       "102537  102537  169635  169636   \n",
       "83320    83320    3767   51558   \n",
       "304304  304304  101579   93681   \n",
       "\n",
       "                                                question1  \\\n",
       "330992   Why do people get white hairs near their temple?   \n",
       "194630               How do you change peoples’ behavior?   \n",
       "102537                  What is it like to live in Texas?   \n",
       "83320      Can you suggest a best budget phone below 15k?   \n",
       "304304  How can I clear/open/delete messages on Snapchat?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "330992  Is there a way to convert some white hair in a...             0  \n",
       "194630      What is the best way to change your behavior?             0  \n",
       "102537                   What it's like to live in Texas?             1  \n",
       "83320     What is the best phone I can get for below 15k?             1  \n",
       "304304  I tried deleting the Snapchat history by selec...             0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us look at a sample of the dataset\n",
    "df_sample = df.sample(5)\n",
    "\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will play with a very small sample of this dataset to save on time. Feel free to train the network on the entire data later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = list(df['is_duplicate'].apply(lambda x: int(x)).values)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of all the question pairs\n",
    "first_question_list = list(df['question1'].apply(lambda x: str(x)).values)\n",
    "second_question_list = list(df['question2'].apply(lambda x: str(x)).values)\n",
    "question_list = list(zip(first_question_list, second_question_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(question_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/shagunsodhani/PyDataConf2017/master/assets/keras-tensorflow-logo.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://raw.githubusercontent.com/shagunsodhani/PyDataConf2017/master/assets/keras-tensorflow-logo.jpg\")\n",
    "# Image taken from: https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from utils.util import *\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers import Embedding, Input, GRU, Dense, Activation, Lambda, BatchNormalization\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(first_question_list + second_question_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence1 = pad_sequences(tokenizer.texts_to_sequences(first_question_list), maxlen=max_len)\n",
    "sequence2 = pad_sequences(tokenizer.texts_to_sequences(second_question_list), maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good to go\n"
     ]
    }
   ],
   "source": [
    "if(len(sequence1) == len(sequence2)):\n",
    "    print(\"Good to go\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Basic ML Preprocessing\n",
    "indices = np.arange(len(sequence1))\n",
    "np.random.shuffle(indices)\n",
    "sequence1 = sequence1[indices]\n",
    "sequence2 = sequence2[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(0.3 * len(sequence1))\n",
    "\n",
    "sequence1_train = sequence1[:-nb_validation_samples]\n",
    "sequence2_train = sequence2[:-nb_validation_samples]\n",
    "labels_train = labels[:-nb_validation_samples]\n",
    "sequence1_val = sequence1[-nb_validation_samples:]\n",
    "sequence2_val = sequence2[-nb_validation_samples:]\n",
    "labels_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 7000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples: \" + str(len(sequence1_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation examples: 3000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of validation examples: \" + str(len(sequence1_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "embeddings_index = get_glove_embeddings(path_to_glove_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the embedding matrix which our model would use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preparing the embedding matrix which our model would use\n",
    "word_index = tokenizer.word_index\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the question into a vector space using a Bidirectional GRU (or LSTM or whatever RNN you believe in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def question_encoder():\n",
    "    return Bidirectional(GRU(units=200), merge_mode='concat', name=\"bidir_gru\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next part is the core of this network and we would walk through it slowly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:  In the implementation, applying this technique usually amounts to insert the BatchNorm layer immediately after fully connected layers, and before non-linearities.\n",
    "\n",
    "From: http://cs231n.github.io/neural-networks-2/#batchnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read: https://www.reddit.com/r/MachineLearning/comments/67gonq/d_batch_normalization_before_or_after_relu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_question_network():\n",
    "    \n",
    "#     Create an input layer\n",
    "    sequence_input = Input(shape=(max_len,), dtype='int32', name=\"input_layer\")\n",
    "    \n",
    "#     Create an embedding layer\n",
    "    embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            embedding_dim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_len,\n",
    "                            trainable=False)\n",
    "    \n",
    "#     Use the embedding layer we just created\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    \n",
    "#     Embeddings are for words, sentences uses encoders\n",
    "    encoded_question = question_encoder()(embedded_sequences)\n",
    "    \n",
    "#     Lets fully connect them\n",
    "    dense1 = Dense(128)(encoded_question)\n",
    "    bn1 = BatchNormalization()(dense1)\n",
    "    relu1 = Activation('relu')(bn1)\n",
    "    \n",
    "#    Make it deep\n",
    "    dense2 = Dense(64)(relu1)\n",
    "    bn2 = BatchNormalization()(dense2)\n",
    "    relu2 = Activation('relu')(bn2)    \n",
    "\n",
    "#     And Deeper\n",
    "    dense3 = Dense(32)(relu2)\n",
    "    bn3 = BatchNormalization()(dense3)\n",
    "    relu3 = Activation('relu')(bn3)\n",
    "\n",
    "#     Now we are in rythm\n",
    "    dense4 = Dense(16)(relu3)\n",
    "    bn4 = BatchNormalization()(dense4)\n",
    "    relu4 = Activation('relu')(bn4)\n",
    "    \n",
    "    output = BatchNormalization()(relu4)\n",
    "    \n",
    "    model = Model(inputs=sequence_input, outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will make the siamese twin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_network():\n",
    "    # network definition\n",
    "    question_network = create_question_network()\n",
    "    \n",
    "#     input to the first head of the network\n",
    "    input1 = Input(shape=(max_len,))\n",
    "    \n",
    "#     input to the second head of the network\n",
    "    input2 = Input(shape=(max_len,))\n",
    "    \n",
    "#     processing the first input\n",
    "    processed1 = question_network(input1)\n",
    "    \n",
    "#     processing the second input\n",
    "    processed2 = question_network(input2)\n",
    "    \n",
    "#     Computing the distance between the transformed inputs.\n",
    "    distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed1, processed2])\n",
    "\n",
    "    \n",
    "    model = Model(inputs=[input1, input2], outputs=distance)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/1\n",
      "7000/7000 [==============================] - 165s - loss: 3.0767 - val_loss: 3.0910\n",
      "Training accuracy: 0.639714285714\n",
      "Validation accuracy: 0.626333333333\n",
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/1\n",
      "7000/7000 [==============================] - 172s - loss: 1.3316 - val_loss: 1.3903\n",
      "Training accuracy: 0.667714285714\n",
      "Validation accuracy: 0.663333333333\n",
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/1\n",
      "6048/7000 [========================>.....] - ETA: 21s - loss: 0.9462"
     ]
    }
   ],
   "source": [
    "model = create_network()\n",
    "\n",
    "optimizer = Adam(lr=0.001, clipnorm=5)\n",
    "model.compile(loss=contrastive_loss, optimizer=optimizer)\n",
    "\n",
    "for i in range(10):\n",
    "    model.fit([sequence1_train, sequence2_train], labels_train,\n",
    "       validation_data=([sequence1_val, sequence2_val], labels_val),\n",
    "       batch_size=28, epochs=1)\n",
    "    \n",
    "    model_labels_train = model.predict([sequence1_train, sequence2_train], batch_size=128)\n",
    "    print(\"Training accuracy: \"+str(compute_accuracy(model_labels_train, labels_train)))\n",
    "    \n",
    "    model_labels_val = model.predict([sequence1_val, sequence2_val], batch_size=128)\n",
    "    print(\"Validation accuracy: \"+str(compute_accuracy(model_labels_val, labels_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_labels_val.ravel() < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(np.equal(model_labels_val.ravel() < 0.5, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compute_accuracy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
